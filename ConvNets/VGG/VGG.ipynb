{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qHgOeIQsNDTq"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "tFakb4P8NNk7"
      },
      "outputs": [],
      "source": [
        "class Block(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, no_layers):\n",
        "        super().__init__()\n",
        "        self.layers = [nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=3, stride=1, padding=1), nn.ReLU()]\n",
        "        for i in range(no_layers-1):\n",
        "            self.layers.append(nn.Conv2d(in_channels=out_channels, out_channels=out_channels, kernel_size=3, stride=1, padding=1))\n",
        "            self.layers.append(nn.ReLU())\n",
        "\n",
        "        self.layers.append(nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "        self.seq = nn.Sequential(*self.layers)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.seq(x)\n",
        "\n",
        "class VGGNet(nn.Module):\n",
        "    def __init__(self, in_channels, classes, layers):\n",
        "        super().__init__()\n",
        "        channels = [in_channels,64,128,256,512,512]\n",
        "        self.blocks = nn.ModuleList([])\n",
        "        for i in range(len(layers)):\n",
        "            self.blocks.append(Block(channels[i], channels[i+1], layers[i]))\n",
        "        \n",
        "        self.fc1 = nn.Linear(7*7*512, 4096)\n",
        "        self.fc2 = nn.Linear(4096, 4096)\n",
        "        self.fc3 = nn.Linear(4096, classes)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        for block in self.blocks:\n",
        "            x = block(x)\n",
        "\n",
        "        x = torch.flatten(x,1)\n",
        "        x = self.relu(self.dropout(self.fc1(x)))\n",
        "        x = self.relu(self.dropout(self.fc2(x)))\n",
        "        x = self.fc3(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ufLQ5aHKTHiL",
        "outputId": "3bb60d1e-88c7-48b8-b80e-9f3557318f30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VGGNet(\n",
            "  (blocks): ModuleList(\n",
            "    (0): Block(\n",
            "      (seq): Sequential(\n",
            "        (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): ReLU()\n",
            "        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (3): ReLU()\n",
            "        (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "      )\n",
            "    )\n",
            "    (1): Block(\n",
            "      (seq): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): ReLU()\n",
            "        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (3): ReLU()\n",
            "        (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "      )\n",
            "    )\n",
            "    (2): Block(\n",
            "      (seq): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): ReLU()\n",
            "        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (3): ReLU()\n",
            "        (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (5): ReLU()\n",
            "        (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (7): ReLU()\n",
            "        (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "      )\n",
            "    )\n",
            "    (3): Block(\n",
            "      (seq): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): ReLU()\n",
            "        (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (3): ReLU()\n",
            "        (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (5): ReLU()\n",
            "        (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (7): ReLU()\n",
            "        (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "      )\n",
            "    )\n",
            "    (4): Block(\n",
            "      (seq): Sequential(\n",
            "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): ReLU()\n",
            "        (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (3): ReLU()\n",
            "        (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (5): ReLU()\n",
            "        (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (7): ReLU()\n",
            "        (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (fc1): Linear(in_features=25088, out_features=4096, bias=True)\n",
            "  (fc2): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "  (fc3): Linear(in_features=4096, out_features=1000, bias=True)\n",
            "  (relu): ReLU()\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            ")\n",
            "torch.Size([16, 1000])\n"
          ]
        }
      ],
      "source": [
        "VGGs = { \n",
        "    \"VGG11\" : [1,1,2,2,2], # 1x64, 1x128, 2x256, 2x512, 2x512\n",
        "    \"VGG13\" : [2,2,2,2,2], # 2x64, 2x128, 2x256, 2x512, 2x512\n",
        "    \"VGG16\" : [2,2,3,3,3], # 2x64, 2x128, 3x256, 3x512, 3x512\n",
        "    \"VGG19\" : [2,2,4,4,4]  # 2x64, 2x128, 4x256, 4x512, 4x512\n",
        "}\n",
        "\n",
        "vgg = VGGNet(3, 1000, VGGs[\"VGG19\"])\n",
        "print(next(vgg.modules()))\n",
        "print(vgg(torch.rand(16,3,224,224)).shape)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "VGG",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}